---
title: Automate training and testing
weight: 4

### FIXED, DO NOT MODIFY
layout: learningpathall
---

## GitHub Actions workflows

### Train Model

In this section, you will automate the training step by executing the _Train Model_ workflow (.github/workflows/train-model.yml) on your Arm-hosted GitHub runner using GitHub Actions. This workflow pulls a [PyTorch 2.3.0 Docker Image compiled with OpenBLAS from DockerHub](https://hub.docker.com/r/armswdev/pytorch-arm-neoverse), and runs the training script `scripts/train_model.py` within that container. The model that is trained on the GTSRB dataset using this script is saved as an artifact of the workflow. 

Inspect the _Train Model_ workflow by opening up the `.github/workflows/train-model.yml` file within your fork:

```yaml
name: Train Model

on:
  workflow_dispatch:

jobs:
  train-model:
    name: Train the Model
    runs-on: ubuntu-22.04-arm-os # Custom ARM64 runner
    container:
      image: armswdev/pytorch-arm-neoverse:r24.07-torch-2.3.0-openblas
      options: --user root
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Run training script
        run: python scripts/train_model.py
      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: traffic_sign_net
          path: ${{ github.workspace }}/models/traffic_sign_net.pth
          retention-days: 5
```
This workflow specifies one job named "Train the model". This job runs in a runner environment specified by `runs-on`. The `runs-on: ubuntu-22.04-arm-os` points to the Arm-based GitHub runner you setup in the first section.

Now, navigate to the _Train Model_ workflow under the _Actions_ tab, and press the _Run workflow_ button. 

![Train_workflow](/images/train_run.png)

You will see the workflow running and it should complete succesfully. Click on the workflow to see the output from each step of the workflow. 

![Actions_train](/images/actions_train.png)

If you expand on the "Run training script" step, you should see the training loss per epoch followed by `Finished Training`.

```output
(...)
Epoch [8/10], Step [400/417], Loss: 0.0230
Epoch [9/10], Step [100/417], Loss: 0.0193
Epoch [9/10], Step [200/417], Loss: 0.0207
Epoch [9/10], Step [300/417], Loss: 0.0204
Epoch [9/10], Step [400/417], Loss: 0.0244
Epoch [10/10], Step [100/417], Loss: 0.0114
Epoch [10/10], Step [200/417], Loss: 0.0168
Epoch [10/10], Step [300/417], Loss: 0.0208
Epoch [10/10], Step [400/417], Loss: 0.0152
Finished Training
```
Confirm that the model has been generated as an artifact in the job's overview.

![#artifact](/images/artifact.png)

This trained model artifact is used to run the next step: testing the model.

### Test Model

Similar to `train_model.py`, there is a workflow called `test-model.yml` which automates running the `test_model.py` script on your Arm-hosted runner. The test job downloads the artifact generated by the training job in the previous step, and runs the inference using PyTorch with OpenBLAS backend from yoru specified container image.

Inspect the _Test Model_ workflow by opening up the `.github/workflows/test-model.yml` file within your fork:

```yaml
name: Test Model

on:
  workflow_dispatch:

jobs:
  test-model:
    name: Test the Model
    runs-on: ubuntu-22.04-arm-os # Custom ARM64 runner
    container:
      image: armswdev/pytorch-arm-neoverse:r24.07-torch-2.3.0-openblas
      options: --user root
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: traffic_sign_net
          run-id: <11-digit run ID>
          github-token: ${{ secrets.GITHUB_TOKEN }}
      - name: Run testing script
        run: python scripts/test_model.py --model traffic_sign_net.pth

```

In order to use the model created by your _Train Model_ job, you will edit the _Test Model_ workflow file.

Open the training job which uploaded the ML model as an artifact by navigating to the _Actions_ tab on your GitHub repository. Choose the _Train Model_ under _All workflows_, and select the latest successful job. The URL from here contains an 11-digit number. Note down this number, which is the _run ID_ from training your model. Open `.github/workflows/test-model.yml`, and update the `run-id` parameter. Save the changes to the file.

![#run-id](/images/run-id.png)

Trigger the _Test Model_ job by clicking the _Run workflow_ button on the _Actions_ tab. 

![#run-workflow](images/run-workflow.png)

You will see the workflow running and it should complete succesfully. Click on the workflow to see the output from each step of the workflow. 

![Actions_test](/images/actions_test.png)

If you click on the "Run testing script" step, you should see the accuracy of the model and a table of the results printed from the PyTorch profiler. To test the model you used PyTorch with the OpenBLAS backend. The output should look similar to:

```output
Accuracy of the model on the test images: 90.48%
-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls
-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
                      model_inference         2.35%     332.000us       100.00%      14.141ms      14.141ms             1
                     aten::max_pool2d         0.10%      14.000us        34.06%       4.817ms       2.409ms             2
        aten::max_pool2d_with_indices        33.97%       4.803ms        33.97%       4.803ms       2.401ms             2
                         aten::linear         0.08%      11.000us        32.98%       4.663ms       2.332ms             2
                          aten::addmm        32.58%       4.607ms        32.71%       4.626ms       2.313ms             2
                         aten::conv2d         0.08%      12.000us        22.37%       3.164ms       1.582ms             2
                    aten::convolution         0.13%      19.000us        22.29%       3.152ms       1.576ms             2
                   aten::_convolution         0.21%      29.000us        22.16%       3.133ms       1.567ms             2
    aten::_nnpack_spatial_convolution        21.88%       3.094ms        21.95%       3.104ms       1.552ms             2
                           aten::relu         0.11%      15.000us         8.17%       1.155ms     385.000us             3
-------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------
Self CPU time total: 14.141ms
```

In the next section, you will learn how to modify the testing workflow to compare the inference performance of the model using PyTorch with a different backend.
